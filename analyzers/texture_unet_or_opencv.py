import os
import requests
import numpy as np
import cv2
from PIL import Image

# ===================================================================================
# MODEL CONFIG
# ===================================================================================

MODEL_PATH = "models/texture.h5"
MODEL_URL = "https://raw.githubusercontent.com/Himika-Mishra/FaceAnalysisApp/main/more_data(3).h5"


def ensure_model():
    """
    ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• .h5 ‚Üí ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å GitHub ‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models/
    - ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á local ‡πÅ‡∏•‡∏∞ Railway (container start ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏´‡∏•‡∏î)
    """
    if os.path.exists(MODEL_PATH):
        return

    try:
        print("‚¨áÔ∏è Downloading Himika-Mishra texture model (more_data(3).h5)...")
        os.makedirs("models", exist_ok=True)
        r = requests.get(MODEL_URL, stream=True, timeout=120)
        total = 0
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(1024 * 1024):
                if chunk:
                    f.write(chunk)
                    total += len(chunk)
        print(f"‚úÖ Model downloaded: {total/1e6:.2f} MB saved to {MODEL_PATH}")
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot download texture model: {e}")


# ===================================================================================
# PREPROCESSING PRO ‚Äî ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á + crop ‡∏´‡∏ô‡πâ‡∏≤ ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå texture
# ===================================================================================

def _illumination_fix(img_rgb: np.ndarray) -> np.ndarray:
    """
    ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ‚Äú‡∏ú‡∏¥‡∏ß‚Äù ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞:
      1) Retinex SSR ‚Üí ‡∏•‡∏î‡πÄ‡∏á‡∏≤/‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏™‡∏á‡πÑ‡∏°‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
      2) CLAHE (LAB) ‚Üí ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î L* (texture ‡∏ú‡∏¥‡∏ß)
      3) Sharpen ‚Üí ‡πÄ‡∏ô‡πâ‡∏ô‡∏£‡∏π‡∏Ç‡∏∏‡∏°‡∏Ç‡∏ô / ‡∏Ç‡∏£‡∏∏‡∏Ç‡∏£‡∏∞‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
    """
    # --- 1) Retinex SSR ---
    img_f = img_rgb.astype(np.float32) + 1.0
    blur = cv2.GaussianBlur(img_f, (0, 0), 60)
    ssr = np.log(img_f) - np.log(blur + 1.0)
    ssr = ssr - ssr.min()
    ssr = (255.0 * ssr / (ssr.max() + 1e-6)).astype(np.uint8)

    # --- 2) CLAHE ‡∏ö‡∏ô L-channel ---
    lab = cv2.cvtColor(ssr, cv2.COLOR_RGB2LAB)
    L, A, B = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    L2 = clahe.apply(L)
    img2 = cv2.cvtColor(cv2.merge([L2, A, B]), cv2.COLOR_LAB2RGB)

    # --- 3) Sharpen (‡πÄ‡∏ô‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î) ---
    blur2 = cv2.GaussianBlur(img2, (0, 0), 3)
    sharp = cv2.addWeighted(img2, 1.5, blur2, -0.5, 0)

    return sharp


def _soft_face_crop(img_rgb: np.ndarray) -> np.ndarray:
    """
    Soft crop: ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÜ
    - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà FaceMesh ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞ robust ‡∏ö‡∏ô‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û
    - ‡∏•‡∏î‡∏ú‡∏•‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏à‡∏≤‡∏Å‡∏ú‡∏° / ‡πÄ‡∏™‡∏∑‡πâ‡∏≠ / background
    """
    h, w, _ = img_rgb.shape
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì: ‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á, ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≤‡∏á/‡∏´‡∏π‡∏≠‡∏≠‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢)
    y1 = int(0.12 * h)
    y2 = int(0.88 * h)
    x1 = int(0.18 * w)
    x2 = int(0.82 * w)
    if y2 <= y1 or x2 <= x1:
        return img_rgb
    return img_rgb[y1:y2, x1:x2]


# ===================================================================================
# DEEP LEARNING BACKEND (U-Net++)
# ===================================================================================

def _dl_score(img_rgb: np.ndarray) -> float | None:
    """
    ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• U-Net++ (.h5) ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
      - input: 224x224 RGB (‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á+crop)
      - output: mask 0..1 (pixel ‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏Ç‡∏∏‡∏°‡∏Ç‡∏ô/‡∏ú‡∏¥‡∏ß‡∏™‡∏≤‡∏Å)
      - risk = ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô pixel ‡∏ó‡∏µ‡πà > 0.5
    ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‚Üí ‡∏Ñ‡∏∑‡∏ô None ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ fallback ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠
    """
    try:
        ensure_model()
        if not os.path.exists(MODEL_PATH):
            print("‚ö†Ô∏è Texture model file not found after ensure_model.")
            return None

        from tensorflow.keras.models import load_model

        model = load_model(MODEL_PATH, compile=False)

        # ----- PREPROCESS PRO -----
        img_fix = _illumination_fix(img_rgb)
        img_crop = _soft_face_crop(img_fix)

        img_resized = cv2.resize(img_crop, (224, 224), interpolation=cv2.INTER_AREA)
        x = np.expand_dims(img_resized.astype(np.float32) / 255.0, axis=0)

        y_pred = model.predict(x, verbose=0)[0]  # [H,W,1] or [H,W]
        mask = y_pred
        if mask.ndim == 3:
            mask = mask[..., 0]

        pores_ratio = float(np.mean(mask > 0.5))
        return float(np.clip(pores_ratio, 0.0, 1.0))

    except Exception as e:
        print(f"‚ö†Ô∏è Texture DL model failed ({e}); fallback to OpenCV metric.")
        return None


# ===================================================================================
# FALLBACK: Pure-OpenCV Texture Metric (GLCM-like + Laplacian)
# ===================================================================================

def _fallback_texture(img_rgb: np.ndarray) -> float:
    """
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OpenCV (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
      - ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á + crop ‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö deep model
      - ‡πÉ‡∏ä‡πâ Laplacian mean + variance ‡∏´‡∏•‡∏±‡∏á Gaussian ‚Üí ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏¥‡∏ß
      - ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ risk 0..1 (‡∏°‡∏≤‡∏Å = ‡∏ú‡∏¥‡∏ß‡∏™‡∏≤‡∏Å / ‡∏£‡∏π‡∏Ç‡∏∏‡∏°‡∏Ç‡∏ô‡∏ä‡∏±‡∏î)
    """
    img_fix = _illumination_fix(img_rgb)
    img_crop = _soft_face_crop(img_fix)

    gray = cv2.cvtColor(img_crop, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0

    # 1) Laplacian roughness
    lap = cv2.Laplacian((gray * 255).astype(np.uint8), cv2.CV_32F, ksize=3)
    lap_mean = float(np.mean(np.abs(lap)))  # ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á = ‡∏ú‡∏¥‡∏ß‡∏°‡∏µ texture ‡∏ä‡∏±‡∏î

    # 2) GLCM-like contrast (approx) ‡∏î‡πâ‡∏ß‡∏¢ Laplacian ‡∏´‡∏•‡∏±‡∏á blur
    gl = cv2.GaussianBlur(gray, (0, 0), 1.0)
    gl2 = cv2.Laplacian((gl * 255).astype(np.uint8), cv2.CV_32F)
    contrast = float(np.var(gl2) / 5000.0)

    # 3) Fusion ‚Üí
    #   - lap_mean ~ [5..25] ‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    #   - contrast ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡πâ‡∏≥ texture
    risk = np.clip(0.65 * (lap_mean / 18.0) + 0.35 * contrast, 0.0, 1.0)
    return float(risk)


# ===================================================================================
# PUBLIC API ‚Äî ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô main.py
# ===================================================================================

def score_texture(img_pil: Image.Image) -> float:
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‚Äú‡∏ú‡∏¥‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô / ‡∏£‡∏π‡∏Ç‡∏∏‡∏°‡∏Ç‡∏ô‚Äù
    return: risk ‚àà [0,1]  (‡∏°‡∏≤‡∏Å = ‡∏ú‡∏¥‡∏ß‡∏™‡∏≤‡∏Å, ‡∏£‡∏π‡∏Ç‡∏∏‡∏°‡∏Ç‡∏ô‡∏Å‡∏ß‡πâ‡∏≤‡∏á/‡∏ä‡∏±‡∏î)
    """
    img_rgb = np.array(img_pil.convert("RGB"))

    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ Deep Model ‡∏Å‡πà‡∏≠‡∏ô
    val = _dl_score(img_rgb)
    if val is not None:
        return float(val)

    # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• load/predict ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚Üí ‡πÉ‡∏ä‡πâ OpenCV ‡πÅ‡∏ó‡∏ô
    return _fallback_texture(img_rgb)


# ===================================================================================
# CLI TEST
# ===================================================================================

if __name__ == "__main__":
    p = "sample_face.jpg"
    if os.path.isfile(p):
        img = Image.open(p)
        s = score_texture(img)
        print(f"üß™ Texture Risk = {s:.3f} ({s*100:.1f}%)")
    else:
        print("‚ÑπÔ∏è Put a sample image at sample_face.jpg to test.")
