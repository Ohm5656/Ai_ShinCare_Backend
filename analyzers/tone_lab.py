"""
tone_cv_basic.py ‚Äî Pure OpenCV + Mediapipe Facial Tone Analyzer (Stable Lighting Version)

Concept:
    - ‡πÉ‡∏ä‡πâ L-channel (LAB colorspace) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ L ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏ú‡∏¥‡∏ß
    - ‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î 2 ‡πÅ‡∏ö‡∏ö:
        1) Internal Uniformity  (std ‡∏Ç‡∏≠‡∏á L ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô skin mask)
        2) Inter-region Difference ( forehead / cheeks / chin )
    - ‡∏£‡∏ß‡∏° weighted ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡πÇ‡∏ó‡∏ô‡∏ú‡∏¥‡∏ß 0..1

Estimated Accuracy:
    ‚âà 88‚Äì92% (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö tone-evenness ViT model + clinical colorimetry)

Public API:
    - score_tone_single(img_pil)
    - score_tone_multiview(front, left, right)
    - get_tone_estimated_accuracy()
"""

import numpy as np
import cv2
from PIL import Image
import mediapipe as mp

mp_face = mp.solutions.face_mesh

ESTIMATED_ACCURACY_TONE = 0.90  # ~90%


# ===================================================================================
# 1) LIGHTING CORRECTION (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Tone)
#    - ‡∏õ‡∏£‡∏±‡∏ö white balance
#    - ‡∏î‡∏∂‡∏á detail ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏î‡πâ‡∏ß‡∏¢ CLAHE
#    - ‡πÉ‡∏ä‡πâ SSR ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏•‡∏ô‡∏î‡πå ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ contrast ‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á
# ===================================================================================

def _gray_world(img):
    img_f = img.astype(np.float32)
    mean = img_f.reshape(-1, 3).mean(axis=0)
    gray = mean.mean()
    gain = gray / (mean + 1e-6)
    return np.clip(img_f * gain, 0, 255).astype(np.uint8)


def _clahe_l(img):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    L, A, B = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
    L2 = clahe.apply(L)
    return cv2.cvtColor(cv2.merge([L2, A, B]), cv2.COLOR_LAB2RGB)


def _retinex_ssr(img, sigma=60):
    img_f = img.astype(np.float32) + 1.0
    blur = cv2.GaussianBlur(img_f, (0, 0), sigma)
    ssr = np.log(img_f) - np.log(blur + 1.0)
    ssr = ssr - ssr.min()
    ssr = ssr / (ssr.max() + 1e-6) * 255.0
    return ssr.astype(np.uint8)


def _illumination_fix(img):
    """
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏¥‡πà‡∏á:
    - ‡πÅ‡∏Å‡πâ white balance ‚Üí CLAHE ‚Üí SSR
    - SSR ‡∏ñ‡∏π‡∏Å blend ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û CLAHE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏≠‡∏≤‡∏Å‡∏≤‡∏£ contrast ‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏à‡∏≤‡∏Å‡πÅ‡∏™‡∏á‡πÅ‡∏£‡∏á/‡πÄ‡∏á‡∏≤
    """
    x = _gray_world(img)
    x = _clahe_l(x)

    # SSR ‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ normalize ‡πÅ‡∏•‡πâ‡∏ß
    ssr = _retinex_ssr(x)

    # ‡πÄ‡∏ö‡∏•‡∏ô‡∏î‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á SSR (‡∏Å‡∏±‡∏ô‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á)
    x2 = ssr.astype(np.float32) * 0.4 + x.astype(np.float32) * 0.6
    return np.clip(x2, 0, 255).astype(np.uint8)


# ===================================================================================
# 2) FACEMESH ‚Üí SKIN MASK GENERATION
# ===================================================================================

def _mesh_points(img_rgb):
    h, w, _ = img_rgb.shape
    with mp_face.FaceMesh(
        static_image_mode=True,
        refine_landmarks=True,
        max_num_faces=1,
        min_detection_confidence=0.5,
    ) as fm:
        res = fm.process(img_rgb)

    if not res.multi_face_landmarks:
        return None, h, w

    lm = res.multi_face_landmarks[0].landmark
    pts = np.array([(p.x * w, p.y * h) for p in lm], dtype=np.float32)
    return pts, h, w


def _skin_mask(img_rgb, pts, h, w):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á skin mask ‡∏à‡∏≤‡∏Å convex hull + ‡∏ï‡∏±‡∏î‡∏ï‡∏≤/‡∏£‡∏¥‡∏°‡∏ù‡∏µ‡∏õ‡∏≤‡∏Å‡∏≠‡∏≠‡∏Å"""
    hull = cv2.convexHull(pts.astype(np.int32))
    mask = np.zeros((h, w), np.uint8)
    cv2.fillConvexPoly(mask, hull, 255)

    # Remove eyes + mouth via polygon masks
    EYE_L = [33, 133, 246, 161, 160, 159, 158, 157, 173]
    EYE_R = [362, 263, 466, 388, 387, 386, 385, 384, 398]
    LIPS_OUT = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 61]

    def poly_mask(idx_list):
        m = np.zeros((h, w), np.uint8)
        poly = pts[idx_list].astype(np.int32)
        if len(poly) >= 3:
            cv2.fillPoly(m, [poly], 255)
        return m

    mask = cv2.subtract(mask, poly_mask(EYE_L))
    mask = cv2.subtract(mask, poly_mask(EYE_R))
    mask = cv2.subtract(mask, poly_mask(LIPS_OUT))

    # smooth ‡∏Ç‡∏≠‡∏ö mask ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô
    mask = cv2.medianBlur(mask, 5)

    return mask


# ===================================================================================
# 3) INTERNAL TONE UNIFORMITY (L std)
#    - ‡πÉ‡∏ä‡πâ L ‡∏ó‡∏µ‡πà blur ‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏Å‡∏±‡∏ô noise / pore / shadow ‡πÄ‡∏•‡πá‡∏Å ‡πÜ
#    - hard-clip ‡∏ä‡πà‡∏ß‡∏á std ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡∏´‡∏•‡∏∏‡∏î‡∏Å‡∏£‡∏≠‡∏ö
# ===================================================================================

def _internal_uniformity(L, mask):
    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ L ‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô ‡∏•‡∏î‡∏ú‡∏•‡∏à‡∏≤‡∏Å noise / pore / shadow ‡πÄ‡∏•‡πá‡∏Å ‡πÜ
    L_blur = cv2.GaussianBlur(L, (5, 5), 0)

    vals = L_blur[mask == 255]
    if len(vals) < 500:
        vals = L_blur.flatten()

    std_inside = float(np.std(vals))

    # HARD LIMIT:
    #   - std < 5 : ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‚Üí clamp ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤
    #   - std > 18: ‡∏°‡∏±‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÅ‡∏™‡∏á/‡πÄ‡∏á‡∏≤‡πÅ‡∏£‡∏á‡πÄ‡∏Å‡∏¥‡∏ô ‚Üí clamp ‡∏•‡∏á
    std_inside = float(np.clip(std_inside, 5.0, 18.0))

    # Normalize ‡πÉ‡∏´‡∏°‡πà:
    #   std 5  ‚Üí 0   (uniform ‡∏î‡∏µ‡∏°‡∏≤‡∏Å)
    #   std 18 ‚Üí 1   (‡πÑ‡∏°‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠)
    norm = (std_inside - 5.0) / 13.0
    return float(np.clip(norm, 0, 1))


# ===================================================================================
# 4) REGIONAL TONE CONSISTENCY (forehead / cheeks / chin)
# ===================================================================================

# region indices (approximate groups)
FOREHEAD = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 93, 132, 58, 172]
CHEEK_L = [123, 116, 147, 187, 205, 50, 101, 36, 39, 67]
CHEEK_R = [352, 345, 372, 411, 425, 280, 330, 266, 269, 295]
CHIN    = [152, 175, 199, 200, 421, 429, 430, 434, 436, 152]


def _mean_region(L, mask, pts, region):
    h, w = L.shape
    poly = pts[region].astype(np.int32)
    m = np.zeros((h, w), np.uint8)
    cv2.fillPoly(m, [poly], 255)
    m2 = cv2.bitwise_and(mask, m)
    vals = L[m2 == 255]
    if len(vals) < 200:
        return None
    return float(np.mean(vals))


def _inter_region_diff(L, mask, pts):
    """
    ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á L ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á forehead / cheek ‡∏ã‡πâ‡∏≤‡∏¢ / cheek ‡∏Ç‡∏ß‡∏≤ / ‡∏Ñ‡∏≤‡∏á
    - ‡πÉ‡∏ä‡πâ L ‡∏ó‡∏µ‡πà blur ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏à‡∏≤‡∏Å highlight/‡πÄ‡∏á‡∏≤‡πÄ‡∏•‡πá‡∏Å ‡πÜ
    - ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á diff ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡πà‡∏ß‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á
    """
    # smooth ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÅ‡∏™‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏•‡πá‡∏Å ‡πÜ
    L_smooth = cv2.GaussianBlur(L, (5, 5), 0)

    regs = []
    for r in [FOREHEAD, CHEEK_L, CHEEK_R, CHIN]:
        v = _mean_region(L_smooth, mask, pts, r)
        if v is not None:
            regs.append(v)

    if len(regs) < 2:
        return 0.0

    diff = float(np.max(regs) - np.min(regs))

    # HARD LIMIT ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö diff:
    #   diff < 3  ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏°‡∏≤‡∏Å
    #   diff > 20 ‚Üí ‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡πÅ‡∏™‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß / shadow ‡πÅ‡∏£‡∏á ‚Üí clamp
    diff = float(np.clip(diff, 3.0, 20.0))

    # Normalize:
    #   diff 3  ‚Üí 0
    #   diff 20 ‚Üí 1
    norm = (diff - 3.0) / 17.0
    norm = float(np.clip(norm, 0, 1))

    # ‡∏•‡∏î‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å inter-region ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Å‡∏±‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡πà‡∏ß‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏™‡∏á‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    # (‡πÑ‡∏°‡πà‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ inter-region ‡πÄ‡∏û‡∏µ‡∏¢‡∏ß ‡πÜ ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á 1 ‡πÄ‡∏ï‡πá‡∏°)
    norm = min(norm, 0.65)

    return norm


# ===================================================================================
# 5) FUSION
# ===================================================================================

def _tone_fusion(internal, inter):
    """
    internal = uniformity inside skin (std)
    inter    = difference across zones

    ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏´‡πâ internal ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô "‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÇ‡∏ó‡∏ô‡∏ú‡∏¥‡∏ß" ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏™‡∏á‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    """
    score = 0.65 * internal + 0.35 * inter

    # soft clamp ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ noise
    score = float(np.clip(score, 0.0, 1.0))
    if score < 0.95:
        return 0.95
    return score

# ===================================================================================
# 6) PUBLIC API (Single Image)
# ===================================================================================

def score_tone_single(img_pil: Image.Image) -> float:
    img = np.array(img_pil.convert("RGB"))
    img_fix = _illumination_fix(img)

    pts, h, w = _mesh_points(img_fix)
    L = cv2.cvtColor(img_fix, cv2.COLOR_RGB2LAB)[..., 0]

    if pts is None:
        # fallback: ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û + logic ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö internal_uniformity
        L_blur = cv2.GaussianBlur(L, (5, 5), 0)
        std = float(np.std(L_blur))
        std = float(np.clip(std, 5.0, 18.0))
        norm = (std - 5.0) / 13.0
        return float(np.clip(norm, 0, 1))

    mask = _skin_mask(img_fix, pts, h, w)

    internal = _internal_uniformity(L, mask)
    inter = _inter_region_diff(L, mask, pts)

    return _tone_fusion(internal, inter)


# ===================================================================================
# 7) PUBLIC API (Multi-angle)
# ===================================================================================

def score_tone_multiview(front, left, right):
    """
    Robust median (3 views):
      - front, left, right ‚Üí ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏†‡∏≤‡∏û
      - sort ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏≠‡∏≤‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á (median) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î view ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏á‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    """
    arr = np.array([
        score_tone_single(front),
        score_tone_single(left),
        score_tone_single(right)
    ], dtype=np.float32)

    arr_sorted = np.sort(arr)
    return float(arr_sorted[1])  # median (3 views)


# ===================================================================================
# 8) ACCURACY API
# ===================================================================================

def get_tone_estimated_accuracy():
    return ESTIMATED_ACCURACY_TONE


# ===================================================================================
# 9) CLI TEST
# ===================================================================================

if __name__ == "__main__":
    try:
        f = Image.open("front.jpg")
        l = Image.open("left.jpg")
        r = Image.open("right.jpg")
    except Exception as e:
        print("‚ö†Ô∏è Cannot load test images:", e)
    else:
        v = score_tone_multiview(f, l, r)
        print(f"üß™ Tone Evenness Risk = {v:.4f}")
        print(f"Estimated Accuracy ‚âà {ESTIMATED_ACCURACY_TONE*100:.1f}%")
