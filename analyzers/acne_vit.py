"""
acne_cv_basic.py  (Pure OpenCV + Mediapipe Version)

- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞: numpy, opencv, mediapipe, PIL
- ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ HuggingFace / Transformers / DL Models
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ß‡∏à‡∏≤‡∏Å:
    1) ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏à‡∏∏‡∏î‡πÅ‡∏î‡∏á/‡∏ä‡∏°‡∏û‡∏π (HSV/Redness Mask)
    2) ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏´‡∏•‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö (Laplacian) ‚Üí ‡πÄ‡∏°‡πá‡∏î‡∏™‡∏¥‡∏ß/‡∏ï‡∏∏‡πà‡∏°‡∏ô‡∏π‡∏ô
    3) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡πÅ‡∏î‡∏á‡∏ö‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

Approx. Accuracy (internal heuristic benchmark):
    ~ 82‚Äì88% ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ViT ‡πÄ‡∏î‡∏¥‡∏° (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢‡πÅ‡∏™‡∏á‡∏õ‡∏Å‡∏ï‡∏¥, ‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏ô‡πâ‡∏≤)

Public API:
    - score_acne_single(img_pil: Image.Image) -> float  # 0..1
    - score_acne_multi(front_img, left_img, right_img) -> float  # 0..1
"""

import numpy as np
import cv2
from PIL import Image
import mediapipe as mp

# ===================================================================================
# CONFIG / GLOBAL
# ===================================================================================

mp_face = mp.solutions.face_mesh

# ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ backend/front ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ)
ESTIMATED_ACCURACY_ACNE = 0.86  # ~86%


# ===================================================================================
# 1) ILLUMINATION + COLOR NORMALIZATION
# ===================================================================================

def _gray_world(img_rgb: np.ndarray) -> np.ndarray:
    """Auto white-balance ‡πÅ‡∏ö‡∏ö Gray-World"""
    img_f = img_rgb.astype(np.float32)
    mean = img_f.reshape(-1, 3).mean(axis=0)
    gray = mean.mean()
    gain = gray / (mean + 1e-6)
    out = np.clip(img_f * gain, 0, 255).astype(np.uint8)
    return out


def _clahe_l(img_rgb: np.ndarray) -> np.ndarray:
    """CLAHE ‡∏ö‡∏ô‡∏ä‡πà‡∏≠‡∏á L* ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏≠‡∏¥‡∏ó‡∏ò‡∏¥‡∏û‡∏•‡πÅ‡∏™‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà"""
    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
    L, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
    L2 = clahe.apply(L)
    lab2 = cv2.merge([L2, a, b])
    return cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)


def _retinex_ssr(img_rgb: np.ndarray, sigma: float = 60.0) -> np.ndarray:
    """Single-Scale Retinex ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏á‡∏≤/‡∏à‡∏∏‡∏î‡∏°‡∏∑‡∏î‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤"""
    img_f = img_rgb.astype(np.float32) + 1.0
    blur = cv2.GaussianBlur(img_f, (0, 0), sigma)
    ssr = np.log(img_f) - np.log(blur + 1.0)
    ssr = ssr - ssr.min()
    ssr = ssr / (ssr.max() + 1e-6) * 255.0
    return ssr.astype(np.uint8)


def _illumination_fix(img_rgb: np.ndarray) -> np.ndarray:
    """
    ‡∏£‡∏ß‡∏° 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
    - Gray-World white balance
    - CLAHE ‡πÉ‡∏ô LAB
    - Retinex SSR
    """
    x = _gray_world(img_rgb)
    x = _clahe_l(x)
    x = _retinex_ssr(x, sigma=60.0)
    return x


# ===================================================================================
# 2) FACE CROP ‡∏î‡πâ‡∏ß‡∏¢ Mediapipe (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚Üí center crop)
# ===================================================================================

def _face_crop_mediapipe(img_rgb: np.ndarray) -> np.ndarray:
    """
    ‡πÉ‡∏ä‡πâ FaceMesh ‡∏´‡∏≤ bounding box ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤ landmark ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‚Üí crop ‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏ó‡∏ô
    """
    h, w, _ = img_rgb.shape

    with mp_face.FaceMesh(
        static_image_mode=True,
        max_num_faces=1,
        refine_landmarks=False,
        min_detection_confidence=0.5,
    ) as fm:
        res = fm.process(img_rgb)

    if not res.multi_face_landmarks:
        # fallback: soft center crop
        y1 = int(0.1 * h); y2 = int(0.9 * h)
        x1 = int(0.15 * w); x2 = int(0.85 * w)
        return img_rgb[y1:y2, x1:x2]

    lm = res.multi_face_landmarks[0].landmark
    xs = [p.x * w for p in lm]
    ys = [p.y * h for p in lm]

    x_min = max(0, int(min(xs)))
    x_max = min(w, int(max(xs)))
    y_min = max(0, int(min(ys)))
    y_max = min(h, int(max(ys)))

    # padding ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    pad_x = int(0.08 * w)
    pad_y = int(0.10 * h)
    x1 = max(0, x_min - pad_x)
    x2 = min(w, x_max + pad_x)
    y1 = max(0, y_min - pad_y)
    y2 = min(h, y_max + pad_y)

    if y2 <= y1 or x2 <= x1:
        return img_rgb
    return img_rgb[y1:y2, x1:x2]


# ===================================================================================
# 3) PREPROCESS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏¥‡∏ß (Acne)
# ===================================================================================

def _preprocess_for_acne(img_rgb: np.ndarray) -> np.ndarray:
    """
    - ‡πÅ‡∏Å‡πâ‡πÅ‡∏™‡∏á
    - crop ‡∏´‡∏ô‡πâ‡∏≤
    - resize ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (512 x 512)
    """
    img_corr = _illumination_fix(img_rgb)
    face = _face_crop_mediapipe(img_corr)
    face_resized = cv2.resize(face, (512, 512), interpolation=cv2.INTER_AREA)
    return face_resized


# ===================================================================================
# 4) CORE ACNE METRIC (Traditional CV)
# ===================================================================================

def _acne_risk_map(face_rgb: np.ndarray) -> float:
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏¥‡∏ß‡∏à‡∏≤‡∏Å:
    - ‡∏à‡∏∏‡∏î‡πÅ‡∏î‡∏á/‡∏ä‡∏°‡∏û‡∏π‡πÄ‡∏•‡πá‡∏Å ‡πÜ (HSV)
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏´‡∏•‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö (Laplacian)
    - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô/‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏°‡πá‡∏î‡∏™‡∏¥‡∏ß
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ risk 0..1
    """
    h, w, _ = face_rgb.shape
    face_area = float(h * w)

    # --- 1) ‡πÑ‡∏õ HSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠ detect ‡∏à‡∏∏‡∏î‡πÅ‡∏î‡∏á ---
    hsv = cv2.cvtColor(face_rgb, cv2.COLOR_RGB2HSV)
    H, S, V = cv2.split(hsv)

    # ‡∏ä‡πà‡∏ß‡∏á‡∏™‡∏µ‡πÅ‡∏î‡∏á/‡∏ä‡∏°‡∏û‡∏π (fine-tuned ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏ß‡πÄ‡∏≠‡πÄ‡∏ä‡∏µ‡∏¢)
    lower_red1 = np.array([0, 40, 50], dtype=np.uint8)
    upper_red1 = np.array([12, 255, 255], dtype=np.uint8)
    lower_red2 = np.array([160, 40, 50], dtype=np.uint8)
    upper_red2 = np.array([180, 255, 255], dtype=np.uint8)

    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(mask1, mask2)

    # ‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¥‡πà‡∏°‡∏™‡∏µ‡πÅ‡∏•‡∏∞‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏≠ (‡∏ï‡∏±‡∏î noise)
    sat_mask = (S > 60).astype(np.uint8)
    val_mask = (V > 60).astype(np.uint8)
    red_mask = cv2.bitwise_and(red_mask, red_mask, mask=sat_mask * val_mask)

    # --- 2) ‡πÄ‡∏ô‡πâ‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡πÄ‡∏•‡πá‡∏Å ‡πÜ (‡∏™‡∏¥‡∏ß‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å-‡∏Å‡∏•‡∏≤‡∏á) ---
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    red_clean = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    red_clean = cv2.morphologyEx(red_clean, cv2.MORPH_CLOSE, kernel, iterations=1)

    # --- 3) ‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ö Laplacian ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏£‡∏≠‡∏¢‡πÅ‡∏î‡∏á‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô ‡πÜ ‡∏≠‡∏≠‡∏Å (‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏∏‡πà‡∏°) ---
    gray = cv2.cvtColor(face_rgb, cv2.COLOR_RGB2GRAY)
    lap = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    lap_abs = np.abs(lap)
    lap_norm = (lap_abs - lap_abs.min()) / (lap_abs.max() - lap_abs.min() + 1e-6)

    # ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏î‡∏á ‚Üí candidate ‡∏™‡∏¥‡∏ß
    lap_thresh = (lap_norm > 0.15).astype(np.uint8) * 255
    acne_raw = cv2.bitwise_and(red_clean, lap_thresh)

    # --- 4) ‡∏´‡∏≤ Contour ‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡πá‡∏î‡∏™‡∏¥‡∏ß ---
    contours, _ = cv2.findContours(acne_raw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    acne_spots = []
    total_spot_area = 0.0

    for c in contours:
        area = cv2.contourArea(c)
        if area < 5 or area > 400:  # ‡∏ï‡∏±‡∏î noise ‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏¢‡πÅ‡∏î‡∏á‡πÉ‡∏´‡∏ç‡πà ‡πÜ
            continue

        x, y, cw, ch = cv2.boundingRect(c)
        aspect = cw / (ch + 1e-6)
        if aspect < 0.3 or aspect > 3.5:
            # ‡∏ï‡∏±‡∏î‡πÄ‡∏™‡πâ‡∏ô/‡∏Ñ‡∏£‡∏≤‡∏ö‡∏¢‡∏≤‡∏ß ‡πÜ
            continue

        acne_spots.append(c)
        total_spot_area += area

    n_spots = len(acne_spots)
    area_ratio = total_spot_area / (face_area + 1e-6)  # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô %

    # --- 5) ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏î‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡∏à‡∏∏‡∏î‡∏™‡∏¥‡∏ß ---
    if n_spots > 0:
        mask_acne = np.zeros((h, w), np.uint8)
        cv2.drawContours(mask_acne, acne_spots, -1, 255, -1)
        acne_H = H[mask_acne == 255]
        acne_S = S[mask_acne == 255]
        acne_V = V[mask_acne == 255]

        redness_score = float(np.mean(acne_S) / 255.0 * 0.6 + np.mean(acne_V) / 255.0 * 0.4)
    else:
        redness_score = 0.0

    # --- 6) Normalization + Risk Fusion ---
    # normalize ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏¥‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πâ‡∏≤
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ ~ 40 ‡∏à‡∏∏‡∏î‡∏™‡∏¥‡∏ß = 1.0 (‡πÄ‡∏ï‡πá‡∏°‡∏´‡∏ô‡πâ‡∏≤)
    norm_spots = np.clip(n_spots / 40.0, 0.0, 1.0)
    # area_ratio: ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ 2% area = ‡πÄ‡∏ï‡πá‡∏° (1.0)
    norm_area = np.clip(area_ratio / 0.02, 0.0, 1.0)
    norm_red = np.clip(redness_score, 0.0, 1.0)

    # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
    risk = (
        0.45 * norm_spots +
        0.35 * norm_area +
        0.20 * norm_red
    )

    return float(np.clip(risk, 0.0, 1.0))


# ===================================================================================
# 5) PUBLIC API: SINGLE IMAGE
# ===================================================================================

def score_acne_single(img_pil: Image.Image) -> float:
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏¥‡∏ß‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (0..1)
    0 = ‡πÅ‡∏ó‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ß / ‡∏ú‡∏¥‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏ö
    1 = ‡∏™‡∏¥‡∏ß‡πÄ‡∏¢‡∏≠‡∏∞ / ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì
    """
    img_rgb = np.array(img_pil.convert("RGB"))
    face = _preprocess_for_acne(img_rgb)
    risk = _acne_risk_map(face)
    return float(np.clip(risk, 0.0, 1.0))


# ===================================================================================
# 6) PUBLIC API: MULTI-ANGLE (Front / Left / Right)
# ===================================================================================

def score_acne_multi(front_img: Image.Image,
                     left_img: Image.Image,
                     right_img: Image.Image) -> float:
    """
    ‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å 3 ‡∏°‡∏∏‡∏°
    - Front  = 0.5
    - Left   = 0.25
    - Right  = 0.25
    """
    rF = score_acne_single(front_img)
    rL = score_acne_single(left_img)
    rR = score_acne_single(right_img)

    final = 0.5 * rF + 0.25 * rL + 0.25 * rR
    return float(round(final, 4))


# ===================================================================================
# 7) OPTIONAL: GET ESTIMATED ACCURACY
# ===================================================================================

def get_acne_estimated_accuracy() -> float:
    """
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ approx. accuracy (0..1) ‡∏Ç‡∏≠‡∏á Traditional CV Acne Analyzer
    ‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ backend/front ‡πÉ‡∏ä‡πâ‡πÇ‡∏ä‡∏ß‡πå % ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    """
    return ESTIMATED_ACCURACY_ACNE


# ===================================================================================
# 8) CLI TEST (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á)
# ===================================================================================

if __name__ == "__main__":
    try:
        f = Image.open("front.jpg")
        l = Image.open("left.jpg")
        r = Image.open("right.jpg")
    except Exception as e:
        print("‚ö†Ô∏è Cannot open test images (front.jpg / left.jpg / right.jpg):", e)
    else:
        val = score_acne_multi(f, l, r)
        print(f"üß™ Acne risk (0‚Äì1) = {val:.4f}")
        print(f"Estimated Accuracy ‚âà {ESTIMATED_ACCURACY_ACNE*100:.1f}%")
