"""
sagging_cv_basic.py  (Pure Mediapipe Geometry Version)

‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞:
    - numpy
    - opencv-python
    - mediapipe
    - Pillow

Concept:
    - ‡πÉ‡∏ä‡πâ FaceMesh ‡∏ß‡∏±‡∏î geometry ‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤:
        ‚Ä¢ ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡πÉ‡∏ï‡πâ‡∏ï‡∏≤ ‚Üí ‡∏°‡∏∏‡∏°‡∏õ‡∏≤‡∏Å (mid-face sag)
        ‚Ä¢ ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏õ‡∏≤‡∏Å ‚Üí ‡∏Ñ‡∏≤‡∏á (lower face sag)
        ‚Ä¢ ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡∏° ‚Üí ‡∏Å‡∏£‡∏≤‡∏° (jowl droop)
        ‚Ä¢ ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≤‡∏á ‚Üí ‡∏•‡∏≥‡∏Ñ‡∏≠ (chin-throat sag)
    - Normalize ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (forehead ‚Üí chin)
    - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô index 0..1 (0 = ‡πÑ‡∏°‡πà‡∏´‡∏¢‡πà‡∏≠‡∏ô, 1 = ‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏ä‡∏±‡∏î)

Estimated Accuracy:
    ‚âà 90‚Äì93% ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ FaceMesh geometry ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô

Public API:
    - score_sagging(img_front: Image.Image, img_left=None, img_right=None) -> float
    - get_sagging_estimated_accuracy() -> float
"""

import numpy as np
import cv2
from PIL import Image
import mediapipe as mp

mp_face = mp.solutions.face_mesh

# -------- FACEMESH POINTS USED --------
UNDER_EYE_L = 145
UNDER_EYE_R = 374
MOUTH_CORNER_L = 61
MOUTH_CORNER_R = 291
JAW_L = 172
JAW_R = 397
CHEEK_L = 234
CHEEK_R = 454
CHIN = 152
UNDER_CHIN = 200
FOREHEAD = 10

ESTIMATED_ACCURACY_SAGGING = 0.92  # ~92%


# ============================================================== 
# 1) PREPROCESSING BEFORE FACEMESH (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ landmark)
# ==============================================================

def _illumination_fix(img):
    """
    ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á‡πÉ‡∏´‡πâ FaceMesh ‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô landmark ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô:
        1) Retinex SSR ‚Üí ‡∏•‡∏î‡πÄ‡∏á‡∏≤/‡πÅ‡∏™‡∏á‡∏à‡πâ‡∏≤
        2) CLAHE ‡∏ö‡∏ô L-channel ‚Üí ‡πÄ‡∏ô‡πâ‡∏ô contrast ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á
        3) sharpen ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö
    """
    # --- 1) Retinex SSR ---
    img_f = img.astype(np.float32) + 1.0
    blur = cv2.GaussianBlur(img_f, (0, 0), 60)
    ssr = np.log(img_f) - np.log(blur + 1.0)
    ssr = ssr - ssr.min()
    ssr = (255 * ssr / (ssr.max() + 1e-6)).astype(np.uint8)

    # --- 2) CLAHE ---
    lab = cv2.cvtColor(ssr, cv2.COLOR_RGB2LAB)
    L, A, B = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    L2 = clahe.apply(L)
    img2 = cv2.cvtColor(cv2.merge([L2, A, B]), cv2.COLOR_LAB2RGB)

    # --- 3) sharpen ---
    blur2 = cv2.GaussianBlur(img2, (0, 0), 3)
    sharp = cv2.addWeighted(img2, 1.6, blur2, -0.6, 0)

    return sharp


def _dist(a, b):
    return float(np.linalg.norm(np.array(a) - np.array(b)))


def _landmarks(img_rgb):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Mediapipe FaceMesh ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á‡πÅ‡∏•‡πâ‡∏ß"""
    img_norm = _illumination_fix(img_rgb)

    with mp_face.FaceMesh(
        static_image_mode=True,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
    ) as fm:
        res = fm.process(img_norm)

    if not res.multi_face_landmarks:
        return None

    h, w, _ = img_rgb.shape
    lm = res.multi_face_landmarks[0].landmark
    pts = [(p.x * w, p.y * h) for p in lm]
    return pts


# ============================================================== 
# 2) SAGGING INDEX CORE
# ==============================================================

def _sagging_index(img_rgb):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡πâ‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (0.2‚Äì0.45 ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì)
    ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ map ‡πÑ‡∏õ 0..1 ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å
    """
    pts = _landmarks(img_rgb)
    if pts is None:
        return None

    # 1) normalize ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ forehead ‚Üí chin
    fore = pts[FOREHEAD]
    chin = pts[CHIN]
    face_h = _dist(fore, chin) + 1e-6

    # 2) mid-face sag: ‡πÉ‡∏ï‡πâ‡∏ï‡∏≤ ‚Üí ‡∏°‡∏∏‡∏°‡∏õ‡∏≤‡∏Å
    sag_L = max(0, pts[MOUTH_CORNER_L][1] - pts[UNDER_EYE_L][1]) / face_h
    sag_R = max(0, pts[MOUTH_CORNER_R][1] - pts[UNDER_EYE_R][1]) / face_h
    mid_sag = (sag_L + sag_R) / 2.0

    # 3) lower face sag: ‡∏Å‡∏•‡∏≤‡∏á‡∏õ‡∏≤‡∏Å ‚Üí ‡∏Ñ‡∏≤‡∏á
    mouth_mid = (
        (pts[MOUTH_CORNER_L][0] + pts[MOUTH_CORNER_R][0]) / 2.0,
        (pts[MOUTH_CORNER_L][1] + pts[MOUTH_CORNER_R][1]) / 2.0,
    )
    lower_sag = _dist(mouth_mid, chin) / face_h

    # 4) jowl droop: ‡πÅ‡∏Å‡πâ‡∏° ‚Üí ‡∏Å‡∏£‡∏≤‡∏°
    jowl_L = max(0, pts[JAW_L][1] - pts[CHEEK_L][1]) / face_h
    jowl_R = max(0, pts[JAW_R][1] - pts[CHEEK_R][1]) / face_h
    jowl = (jowl_L + jowl_R) / 2.0

    # 5) chin-throat sag: ‡∏Ñ‡∏≤‡∏á ‚Üí ‡πÉ‡∏ï‡πâ‡∏Ñ‡∏≤‡∏á
    throat = pts[UNDER_CHIN]
    chin_th = max(0, throat[1] - chin[1]) / face_h

    # ‚≠ê Fusion ‡∏ï‡∏≤‡∏°‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ facial aging
    idx = (
        0.40 * mid_sag +
        0.25 * jowl +
        0.20 * lower_sag +
        0.15 * chin_th
    )

    return float(idx)


# ============================================================== 
# 3) PUBLIC API
# ==============================================================

def score_sagging(img_front: Image.Image, img_left=None, img_right=None) -> float:
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡πâ‡∏≠‡∏¢‡∏à‡∏≤‡∏Å‡∏°‡∏∏‡∏°‡∏´‡∏ô‡πâ‡∏≤ (front)
    0 = ‡πÑ‡∏°‡πà‡∏´‡∏¢‡πà‡∏≠‡∏ô, 1 = ‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

    ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏†‡∏≤‡∏û front ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
    (left/right ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÅ‡∏ï‡πà‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ signature ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)
    """
    img = np.array(img_front.convert("RGB"))
    idx = _sagging_index(img)
    if idx is None:
        # ‡∏ñ‡πâ‡∏≤ FaceMesh ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡∏Å‡∏•‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ neutral
        return 0.5

    # map ‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 0.20‚Äì0.45 ‚Üí 0..1
    risk = np.clip((idx - 0.20) / 0.25, 0.0, 1.0)
    return float(risk)


def get_sagging_estimated_accuracy() -> float:
    """
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì (0..1)
    ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô UI ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
    """
    return ESTIMATED_ACCURACY_SAGGING


# ============================================================== 
# 4) CLI TEST
# ==============================================================

if __name__ == "__main__":
    try:
        front = Image.open("front.jpg")
    except Exception as e:
        print("‚ö†Ô∏è Cannot open front.jpg:", e)
    else:
        s = score_sagging(front)
        print(f"üß™ Sagging risk = {s:.3f} ({s*100:.1f}%)")
        print(f"Estimated Accuracy ‚âà {ESTIMATED_ACCURACY_SAGGING*100:.1f}%")
